{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nvvYFFNaf12H"
      },
      "outputs": [],
      "source": [
        "language = 'pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVJe979lA_8D"
      },
      "source": [
        "# 1. Grava칞칚o de 츼udio Com Python (e Uma Pitada de JavaScript) 游꿗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQj2WnrRAoXR",
        "outputId": "28da82b4-50f9-4f7d-8497-965b79dc37be"
      },
      "outputs": [],
      "source": [
        "# Refer칡ncia: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# C칩digo JavaScript para gravar 치udio do usu치rio usando a \"MediaStream Recording API\"\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  # Executa o c칩digo JavaScript para gravar o 치udio\n",
        "  display(Javascript(RECORD))\n",
        "  # Recebe o 치udio gravado como resultado do JavaScript\n",
        "  js_result = output.eval_js('record(%s)' % (sec * 1000))\n",
        "   # Decodifica o 치udio em base64\n",
        "  audio = b64decode(js_result.split(',')[1])\n",
        "  # Salva o 치udio em um arquivo\n",
        "  file_name = 'request_audio.wav'\n",
        "  with open(file_name, 'wb') as f:\n",
        "    f.write(audio)\n",
        "  # Retorna o caminho do arquivo de 치udio (pasta padr칚o do Google Colab)\n",
        "  return f'/content/{file_name}'\n",
        "\n",
        "# Grava o 치udio do usu치rio por um tempo determinado (padr칚o 5 segundos)\n",
        "print('Ouvindo...\\n')\n",
        "record_file = record()\n",
        "\n",
        "# Exibe o 치udio gravado\n",
        "display(Audio(record_file, autoplay=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVtxLeSEGEqE"
      },
      "source": [
        "# 2. Reconhecimento de Fala com Whisper (OpenAI) 游"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B0L7dwnuGMSj",
        "outputId": "97a7b594-128c-46f0-b49d-abb79eabfd7b"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H18caD49dzQ_",
        "outputId": "29034df0-cb25-445f-ea40-dfe7f9496f88"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "# Selecione o modelo do Whisper que melhor atenda 맙 suas necessidades:\n",
        "# https://github.com/openai/whisper#available-models-and-languages\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "# Transcreve o audio gravado anteriormente.\n",
        "result = model.transcribe(record_file, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TalupqHJRxir"
      },
      "source": [
        "# 3. Integra칞칚o com a API do ChatGPT 游눫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y_GodW9JR3R-",
        "outputId": "8dc6a837-4fb7-4034-8d0d-7bb783bc0070"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfQYt9oUhL8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Documenta칞칚o Oficial da API OpenAI: https://platform.openai.com/docs/api-reference/introduction\n",
        "# Informa칞칫es sobre o Per칤odo Gratuito: https://help.openai.com/en/articles/4936830\n",
        "\n",
        "# Para gerar uma API Key:\n",
        "# 1. Crie uma conta na OpenAI\n",
        "# 2. Acesse a se칞칚o \"API Keys\"\n",
        "# 3. Clique em \"Create API Key\"\n",
        "# Link direto: https://platform.openai.com/account/api-keys\n",
        "\n",
        "# Substitua o texto \"TODO\" por sua API Key da OpenAI, ela ser치 salva como uma vari치vel de ambiente.\n",
        "os.environ['OPENAI_API_KEY'] = 'TODO'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wt7K280SSNp",
        "outputId": "91f2ca81-62fb-400d-ce43-ae2aca343965"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Configura a chave de API da OpenAI usando a vari치vel de ambiente 'OPENAI_API_KEY'\n",
        "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "# Envia uma requisi칞칚o  API do ChatCompletion usando o modelo GPT-3.5 Turbo\n",
        "# Lembrando que, a vari치vel 'transcription' cont칠m a transcri칞칚o do nosso 치udio.\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[ { \"role\": \"user\", \"content\": transcription } ]\n",
        ")\n",
        "\n",
        "# Obt칠m a resposta gerada pelo ChatGPT\n",
        "chatgpt_response = response.choices[0].message.content\n",
        "print(chatgpt_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3mRPF-Ka-et"
      },
      "source": [
        "# 4. Sintetizando a Resposta do ChatGPT Como Voz (gTTS) 游댉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ztyl4KSGbP5E",
        "outputId": "bdc9101e-0e3a-4d44-85c0-93eb1404c008"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bAPhZQChbjfb",
        "outputId": "3fc1ae7a-460a-4455-ac44-1602d4790f4f"
      },
      "outputs": [],
      "source": [
        "from gtts import  gTTS\n",
        "\n",
        "# Cria um objeto gTTS com a resposta gerada pelo ChatGPT e a l칤ngua que ser치 sintetizada em voz (vari치vel \"language\").\n",
        "gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)\n",
        "\n",
        "# Salva o 치udio da resposta no arquivo especificado (pasta padr칚o do Google Colab)\n",
        "response_audio = \"/content/response_audio.wav\"\n",
        "gtts_object.save(response_audio)\n",
        "\n",
        "# Reproduz o 치udio da resposta salvo no arquivo\n",
        "display(Audio(response_audio, autoplay=True))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xVJe979lA_8D"
      ],
      "gpuClass": "premium",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
